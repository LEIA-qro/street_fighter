{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Street Fighter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing gym and retro.\n",
    "- Loading the ROM file.\n",
    "- Analysing the game space.\n",
    "- Testing the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import gym, retro\n",
    "\n",
    "import time  # For slowing down fights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.21.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: gym-retro==0.8.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from gym==0.21.0) (1.24.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from gym==0.21.0) (3.1.1)\n",
      "Requirement already satisfied: pyglet==1.*,>=1.3.2 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from gym-retro==0.8.0) (1.5.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\diego\\Desktop\\street_fighter\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting torch==2.1.2+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp38-cp38-win_amd64.whl (2474.0 MB)\n",
      "Collecting torchvision==0.16.2+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp38-cp38-win_amd64.whl (5.6 MB)\n",
      "Collecting torchaudio==2.1.2+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.1.2%2Bcu121-cp38-cp38-win_amd64.whl (4.0 MB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from torch==2.1.2+cu121) (4.13.2)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting networkx\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting sympy\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from torchvision==0.16.2+cu121) (1.24.4)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Using cached pillow-10.4.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp38-cp38-win_amd64.whl (17 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.3-cp38-cp38-win_amd64.whl (105 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, MarkupSafe, urllib3, sympy, networkx, jinja2, idna, fsspec, filelock, charset-normalizer, certifi, torch, requests, pillow, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 certifi-2025.8.3 charset-normalizer-3.4.3 filelock-3.16.1 fsspec-2025.3.0 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.1 pillow-10.4.0 requests-2.32.4 sympy-1.13.3 torch-2.1.2+cu121 torchaudio-2.1.2+cu121 torchvision-0.16.2+cu121 urllib3-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\diego\\Desktop\\street_fighter\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3==1.7.0\n",
      "  Using cached stable_baselines3-1.7.0-py3-none-any.whl (171 kB)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from stable-baselines3==1.7.0) (2.1.2+cu121)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from stable-baselines3==1.7.0) (3.1.1)\n",
      "Requirement already satisfied: gym==0.21 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from stable-baselines3==1.7.0) (0.21.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from stable-baselines3==1.7.0) (1.24.4)\n",
      "Collecting importlib-metadata~=4.13\n",
      "  Using cached importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.7.5-cp38-cp38-win_amd64.whl (7.5 MB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3==1.7.0) (3.20.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.7.0) (1.13.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.7.0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.7.0) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.7.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.7.0) (3.1.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.7.0) (3.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from jinja2->torch>=1.11->stable-baselines3==1.7.0) (2.1.5)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.7-cp38-cp38-win_amd64.whl (55 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.57.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (10.4.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.1.1-cp38-cp38-win_amd64.whl (477 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==1.7.0) (1.17.0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from sympy->torch>=1.11->stable-baselines3==1.7.0) (1.3.0)\n",
      "Installing collected packages: tzdata, pytz, pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, pandas, matplotlib, importlib-metadata, stable-baselines3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 8.5.0\n",
      "    Uninstalling importlib-metadata-8.5.0:\n",
      "      Successfully uninstalled importlib-metadata-8.5.0\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.57.0 importlib-metadata-4.13.0 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.7.5 pandas-2.0.3 pyparsing-3.1.4 pytz-2025.2 stable-baselines3-1.7.0 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\diego\\Desktop\\street_fighter\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Using cached optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Collecting sqlalchemy>=1.4.2\n",
      "  Using cached sqlalchemy-2.0.43-cp38-cp38-win_amd64.whl (2.1 MB)\n",
      "Collecting alembic>=1.5.0\n",
      "  Using cached alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting PyYAML\n",
      "  Using cached pyyaml-6.0.3.tar.gz (130 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from optuna) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.13.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (6.4.5)\n",
      "Collecting Mako\n",
      "  Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
      "Collecting greenlet>=1\n",
      "  Using cached greenlet-3.1.1-cp38-cp38-win_amd64.whl (298 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Building wheels for collected packages: PyYAML\n",
      "  Building wheel for PyYAML (PEP 517): started\n",
      "  Building wheel for PyYAML (PEP 517): finished with status 'done'\n",
      "  Created wheel for PyYAML: filename=PyYAML-6.0.3-cp38-cp38-win_amd64.whl size=45380 sha256=d0e4648c226a3665520031c64b657aaf99a845816d5e5e2bdf870d04a51c3514\n",
      "  Stored in directory: c:\\users\\diego\\appdata\\local\\pip\\cache\\wheels\\60\\9b\\bc\\8c54c7c157a008210f4d6ddfce9e9c5274162b18c5832f8e24\n",
      "Successfully built PyYAML\n",
      "Installing collected packages: greenlet, sqlalchemy, Mako, tqdm, PyYAML, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 PyYAML-6.0.3 alembic-1.14.1 colorlog-6.9.0 greenlet-3.1.1 optuna-4.5.0 sqlalchemy-2.0.43 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\diego\\Desktop\\street_fighter\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shimmy>=2.0\n",
      "  Using cached Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
      "Collecting gymnasium>=1.0.0a1\n",
      "  Using cached gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from shimmy>=2.0) (1.24.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.13.2)\n",
      "Collecting farama-notifications>=0.0.1\n",
      "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium>=1.0.0a1->shimmy>=2.0) (3.20.2)\n",
      "Installing collected packages: farama-notifications, gymnasium, shimmy\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-1.1.1 shimmy-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\diego\\Desktop\\street_fighter\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym==0.21.0 gym-retro==0.8.0\n",
    "%pip install opencv-python matplotlib\n",
    "%pip install torch==2.1.2+cu121 torchvision==0.16.2+cu121 torchaudio==2.1.2+cu121 --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install stable-baselines3==1.7.0\n",
    "%pip install optuna\n",
    "%pip install \"shimmy>=2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! PyTorch can use the GPU.\n",
      "GPU Name: NVIDIA GeForce GTX 1050\n",
      "Current Device ID: 0\n",
      "Number of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use the GPU.\")\n",
    "    \n",
    "    # Get the name of the GPU\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"GPU Name: {gpu_name}\")\n",
    "    \n",
    "    # Get the current GPU device\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(f\"Current Device ID: {current_device}\")\n",
    "    \n",
    "    # Get the total number of GPUs available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is using the CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n",
      "Retro version: 0.8.0\n",
      "Gym version: 0.21.0\n"
     ]
    }
   ],
   "source": [
    "# Optional: Check versions\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Retro version: {retro.__version__}\")\n",
    "print(f\"Gym version: {gym.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Check retro-compatible rom games\n",
    "\n",
    "# retro.data.list_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start game environment\n",
    "env = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis')\n",
    "\n",
    "\n",
    "# Closes game environment since we can only run one at a time\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample the actions available - MultiBinary\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 12,  33,  62],\n",
       "        [ 67,  31,  35],\n",
       "        [255, 134,  69],\n",
       "        ...,\n",
       "        [166, 107, 227],\n",
       "        [ 58, 193, 154],\n",
       "        [143, 233,  16]],\n",
       "\n",
       "       [[191,  69, 139],\n",
       "        [189,  28, 193],\n",
       "        [131, 173, 113],\n",
       "        ...,\n",
       "        [ 88, 158, 100],\n",
       "        [233, 180, 228],\n",
       "        [218, 187,  57]],\n",
       "\n",
       "       [[ 72, 250, 122],\n",
       "        [ 63,  46,  97],\n",
       "        [208,  65, 171],\n",
       "        ...,\n",
       "        [156, 126,  69],\n",
       "        [ 61, 213, 171],\n",
       "        [130,  72, 231]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[130, 145,  36],\n",
       "        [ 33,  64,  70],\n",
       "        [ 74,  98,  69],\n",
       "        ...,\n",
       "        [249, 196,  38],\n",
       "        [166, 178,  89],\n",
       "        [227,  96, 102]],\n",
       "\n",
       "       [[ 76, 105, 197],\n",
       "        [ 48,   3, 117],\n",
       "        [ 52, 106, 228],\n",
       "        ...,\n",
       "        [ 37,  97, 207],\n",
       "        [230, 225, 223],\n",
       "        [205,  34, 105]],\n",
       "\n",
       "       [[ 36,  44, 255],\n",
       "        [141, 144, 200],\n",
       "        [ 86, 188,  69],\n",
       "        ...,\n",
       "        [208, 133, 206],\n",
       "        [215,  14, 254],\n",
       "        [ 38, 206,   2]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample the observation space\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Render environment\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# We take random actions inside the environment\u001b[39;00m\n\u001b[0;32m     22\u001b[0m obs, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample())\n",
      "File \u001b[1;32mc:\\Code\\Street Fighter\\venv\\lib\\site-packages\\retro\\retro_env.py:230\u001b[0m, in \u001b[0;36mRetroEnv.render\u001b[1;34m(self, mode, close)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassic_control\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrendering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleImageViewer\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer \u001b[38;5;241m=\u001b[39m SimpleImageViewer()\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer\u001b[38;5;241m.\u001b[39misopen\n",
      "File \u001b[1;32mc:\\Code\\Street Fighter\\venv\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py:441\u001b[0m, in \u001b[0;36mSimpleImageViewer.imshow\u001b[1;34m(self, arr)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed in an image with the wrong number shape\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m image \u001b[38;5;241m=\u001b[39m pyglet\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mImageData(\n\u001b[0;32m    439\u001b[0m     arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr\u001b[38;5;241m.\u001b[39mtobytes(), pitch\u001b[38;5;241m=\u001b[39marr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m    440\u001b[0m )\n\u001b[1;32m--> 441\u001b[0m texture \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_texture\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    442\u001b[0m gl\u001b[38;5;241m.\u001b[39mglTexParameteri(gl\u001b[38;5;241m.\u001b[39mGL_TEXTURE_2D, gl\u001b[38;5;241m.\u001b[39mGL_TEXTURE_MAG_FILTER, gl\u001b[38;5;241m.\u001b[39mGL_NEAREST)\n\u001b[0;32m    443\u001b[0m texture\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth\n",
      "File \u001b[1;32mc:\\Code\\Street Fighter\\venv\\lib\\site-packages\\pyglet\\image\\__init__.py:835\u001b[0m, in \u001b[0;36mImageData.get_texture\u001b[1;34m(self, rectangle, force_rectangle)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_texture\u001b[39m(\u001b[38;5;28mself\u001b[39m, rectangle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, force_rectangle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_texture \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    834\u001b[0m             (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_texture\u001b[38;5;241m.\u001b[39m_is_rectangle \u001b[38;5;129;01mand\u001b[39;00m force_rectangle)):\n\u001b[1;32m--> 835\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_texture \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_texture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTexture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrectangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_rectangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_texture\n",
      "File \u001b[1;32mc:\\Code\\Street Fighter\\venv\\lib\\site-packages\\pyglet\\image\\__init__.py:821\u001b[0m, in \u001b[0;36mImageData.create_texture\u001b[1;34m(self, cls, rectangle, force_rectangle)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a texture containing this image.\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \n\u001b[0;32m    800\u001b[0m \u001b[38;5;124;03mIf the image's dimensions are not powers of 2, a TextureRegion of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m:rtype: cls or cls.region_class\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    820\u001b[0m internalformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_internalformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[1;32m--> 821\u001b[0m texture \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternalformat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrectangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_rectangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchor_x \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchor_y:\n\u001b[0;32m    824\u001b[0m     texture\u001b[38;5;241m.\u001b[39manchor_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchor_x\n",
      "File \u001b[1;32mc:\\Code\\Street Fighter\\venv\\lib\\site-packages\\pyglet\\image\\__init__.py:1467\u001b[0m, in \u001b[0;36mTexture.create\u001b[1;34m(cls, width, height, internalformat, rectangle, force_rectangle, min_filter, mag_filter)\u001b[0m\n\u001b[0;32m   1465\u001b[0m glGenTextures(\u001b[38;5;241m1\u001b[39m, byref(\u001b[38;5;28mid\u001b[39m))\n\u001b[0;32m   1466\u001b[0m glBindTexture(target, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m-> 1467\u001b[0m \u001b[43mglTexParameteri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGL_TEXTURE_MIN_FILTER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_filter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1468\u001b[0m glTexParameteri(target, GL_TEXTURE_MAG_FILTER, mag_filter)\n\u001b[0;32m   1470\u001b[0m blank \u001b[38;5;241m=\u001b[39m (GLubyte \u001b[38;5;241m*\u001b[39m (texture_width \u001b[38;5;241m*\u001b[39m texture_height \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m))()\n",
      "File \u001b[1;32mc:\\Code\\Street Fighter\\venv\\lib\\site-packages\\pyglet\\gl\\lib.py:87\u001b[0m, in \u001b[0;36merrcheck\u001b[1;34m(result, func, arguments)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mGLException\u001b[39;00m(\u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21merrcheck\u001b[39m(result, func, arguments):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _debug_gl_trace:\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test to see everything working\n",
    "\n",
    "# Reset game to starting state\n",
    "obs = env.reset()\n",
    "\n",
    "# Flag to false\n",
    "done = False\n",
    "\n",
    "# We only play one game\n",
    "for game in range(1):\n",
    "\n",
    "    # If game is not over.\n",
    "    while not done:\n",
    "        if done:\n",
    "            # We reset the game\n",
    "            obs = env.reset()\n",
    "\n",
    "        # Render environment\n",
    "        env.render()\n",
    "\n",
    "        # We take random actions inside the environment\n",
    "        obs, reward, done, info = env.step(env.action_space.sample())\n",
    "\n",
    "        # We slow down the renders so they are watchable\n",
    "        time.sleep(0)\n",
    "\n",
    "        # We print the reward\n",
    "        print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Once the testing is finished we close the environment and see what happened.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m----> 4\u001b[0m \u001b[43minfo\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'info' is not defined"
     ]
    }
   ],
   "source": [
    "# Once the testing is finished we close the environment and see what happened.\n",
    "\n",
    "env.close()\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation preprocessing:\n",
    "1. Calculate change in pixels to capture movement (frame delta).\n",
    "2. Increase game efficiency by grayscaling and reshaping frames from 200x256x3 to 84x84x1  (153,600 pixels vs 7,056) for faster training.\n",
    "\n",
    "Action preprocessing:\n",
    "1. Filtering actions (parameters).\n",
    "2. Redefine reward functions based on score (possibility of basing it on enemy_health and health)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-pythonNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\diego\\Desktop\\street_fighter\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: numpy<2.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from opencv-python) (1.24.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "# Install open cv\n",
    "%pip install opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries necessary for data preprocessing.\n",
    "\n",
    "from gym import Env  # Base environment class for a wrapper\n",
    "from gym.spaces import MultiBinary, Box  # Ensure we pick the correct action space type. (Space shapes for the environment)\n",
    "\n",
    "import numpy as np  # To calculate frame delta\n",
    "import cv2  # For grayscaling\n",
    "\n",
    "from matplotlib import pyplot as plt  # For plotting observation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom environment\n",
    "class StreetFighter(Env):\n",
    "    def __init__(self):\n",
    "\n",
    "        # Inherit from our base environment\n",
    "        super().__init__()\n",
    "\n",
    "        # Specify action and observation spaces\n",
    "        self.observation_space = Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)  # We create our observation space based on the new size and colors\n",
    "        self.action_space = MultiBinary(12)  # We replicate the base action environment\n",
    "\n",
    "        # Startup and instance the game\n",
    "        # The second parameter will limit actions to only valid ones.\n",
    "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis', use_restricted_actions = retro.Actions.FILTERED)\n",
    "\n",
    "    def reset(self):\n",
    "        # Return first frame, preprocess the frame, and define score back to 0.\n",
    "\n",
    "        self.previous_frame = np.zeros(self.game.observation_space.shape)\n",
    "\n",
    "        obs = self.game.reset()  # Will return our observation\n",
    "        obs = self.preprocess(obs)  # We preprocess the observation\n",
    "\n",
    "        self.health = 176\n",
    "        self.enemy_health = 176\n",
    "        \n",
    "        # Game delta = Current_frame - Previous_frame\n",
    "        # Preprocess\n",
    "        self.previous_frame = obs\n",
    "\n",
    "        # Attribute to hold delta score.\n",
    "        self.score = 0\n",
    "\n",
    "        return obs\n",
    "    \n",
    "    def preprocess(self, observation):\n",
    "        # Grayscale, and resize frame\n",
    "        \n",
    "        # Grayscaling\n",
    "        gray = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Resizing\n",
    "        resize = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        channel = np.reshape(resize, (84, 84, 1))  # We add the grayscale layer since its what gym expects\n",
    "\n",
    "        return channel\n",
    "\n",
    "    def step(self, action):\n",
    "        # We take a step, preprocess the observation, calculate frame delta and reshape the reward function\n",
    "\n",
    "        # Take a step\n",
    "        obs, reward, done, info = self.game.step(action)  # New step based on an action\n",
    "\n",
    "        obs = self.preprocess(obs)  # We preprocess the observation\n",
    "\n",
    "        # Frame delta\n",
    "\n",
    "        # We subtract the current one from the previous one and then we set the current as the last one.\n",
    "        frame_delta = obs  # - self.previous_frame\n",
    "        # self.previous_frame = obs\n",
    "\n",
    "        # Reshape the reward function based on relative score\n",
    "        # reward = info['score'] - self.score  # Current reward minus the previous score\n",
    "        # self.score = info['score']  # We set our score to the current score.\n",
    "        delta_enemy = self.enemy_health - info['enemy_health']\n",
    "        delta_self = info['health'] - self.health\n",
    "\n",
    "        reward = delta_enemy * 2 + delta_self\n",
    "\n",
    "\n",
    "       # Update values\n",
    "        self.health = info['health']\n",
    "        self.enemy_health = info['enemy_health'] \n",
    "\n",
    "        return frame_delta, reward, done, info\n",
    "\n",
    "\n",
    "    def render(self, *args, **kwargs):\n",
    "        # We render the game\n",
    "        self.game.render()\n",
    "\n",
    "    def close(self):\n",
    "        # We close the game\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# We close any environment that could be open\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "# We close any environment that could be open\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StreetFighter()  # We instance the created class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiBinary(12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "500\n",
      "500\n",
      "1000\n",
      "500\n",
      "1500\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "300\n",
      "300\n",
      "400\n",
      "1000\n",
      "100\n",
      "1000\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Test to see everything working\n",
    "\n",
    "# Reset game to starting state\n",
    "obs = env.reset()\n",
    "\n",
    "# Flag to false\n",
    "done = False\n",
    "\n",
    "# We only play one game\n",
    "for game in range(1):\n",
    "\n",
    "    # If game is not over.\n",
    "    while not done:\n",
    "        if done:\n",
    "            # We reset the game\n",
    "            obs = env.reset()\n",
    "\n",
    "        # Render environment\n",
    "        env.render()\n",
    "\n",
    "        # We take random actions inside the environment\n",
    "        obs, reward, done, info = env.step(env.action_space.sample())\n",
    "\n",
    "        # We slow down the renders so they are watchable\n",
    "        time.sleep(0)\n",
    "\n",
    "        # We print the reward\n",
    "        if reward > 0:\n",
    "            print(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use PyTorch, Stable Baselines3 and Optuna to get the model's best training parameters.\n",
    "\n",
    "For PPO (Proximal Policy Optimization) we will tune the following hyperparameters:\n",
    "- n_steps: batch size (frames in buffer)\n",
    "- gamma: discount rate for calculating returns\n",
    "- learning_rate: learning coefficient for optimizer\n",
    "- clip_range: clipping amount for advantage calculation\n",
    "- gae_lambda: advantages smoothing parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch: https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting torch==2.0.1+cu118\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp38-cp38-win_amd64.whl (2619.2 MB)\n",
      "Collecting torchvision==0.15.2+cu118\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp38-cp38-win_amd64.whl (4.9 MB)\n",
      "Collecting jinja2\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\code\\street fighter\\venv\\lib\\site-packages (from torch==2.0.1+cu118) (4.13.2)\n",
      "Collecting filelock\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting sympy\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Collecting networkx\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting requests\n",
      "  Downloading https://download.pytorch.org/whl/requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: numpy in c:\\code\\street fighter\\venv\\lib\\site-packages (from torchvision==0.15.2+cu118) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from torchvision==0.15.2+cu118) (10.4.0)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp38-cp38-win_amd64.whl (17 kB)\n",
      "Collecting networkx\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading https://download.pytorch.org/whl/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading https://download.pytorch.org/whl/certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading https://download.pytorch.org/whl/urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading https://download.pytorch.org/whl/idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, MarkupSafe, urllib3, sympy, networkx, jinja2, idna, filelock, charset-normalizer, certifi, torch, requests, torchvision\n",
      "Successfully installed MarkupSafe-2.1.5 certifi-2022.12.7 charset-normalizer-2.1.1 filelock-3.13.1 idna-3.4 jinja2-3.1.4 mpmath-1.3.0 networkx-3.0 requests-2.28.1 sympy-1.13.3 torch-2.0.1+cu118 torchvision-0.15.2+cu118 urllib3-1.26.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Code\\Street Fighter\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.1.2+cu121 torchvision==0.16.2+cu121 torchaudio==2.1.2+cu121 --extra-index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stable Baselines3: https://stable-baselines3.readthedocs.io/en/master/guide/install.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3==1.7.0Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Code\\Street Fighter\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading stable_baselines3-1.7.0-py3-none-any.whl (171 kB)\n",
      "Requirement already satisfied: numpy in c:\\code\\street fighter\\venv\\lib\\site-packages (from stable-baselines3==1.7.0) (1.24.4)\n",
      "Requirement already satisfied: gym==0.21 in c:\\code\\street fighter\\venv\\lib\\site-packages (from stable-baselines3==1.7.0) (0.21.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\code\\street fighter\\venv\\lib\\site-packages (from stable-baselines3==1.7.0) (3.1.1)\n",
      "Requirement already satisfied: matplotlib in c:\\code\\street fighter\\venv\\lib\\site-packages (from stable-baselines3==1.7.0) (3.7.5)\n",
      "Collecting importlib-metadata~=4.13\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pandas in c:\\code\\street fighter\\venv\\lib\\site-packages (from stable-baselines3==1.7.0) (2.0.3)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\code\\street fighter\\venv\\lib\\site-packages (from stable-baselines3==1.7.0) (2.0.1+cu118)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\code\\street fighter\\venv\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3==1.7.0) (3.20.2)\n",
      "Requirement already satisfied: sympy in c:\\code\\street fighter\\venv\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.7.0) (1.13.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\code\\street fighter\\venv\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.7.0) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\code\\street fighter\\venv\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.7.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\code\\street fighter\\venv\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.7.0) (3.1.4)\n",
      "Requirement already satisfied: filelock in c:\\code\\street fighter\\venv\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.7.0) (3.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from jinja2->torch>=1.11->stable-baselines3==1.7.0) (2.1.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (4.57.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (6.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\code\\street fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (3.1.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\code\\street fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\code\\street fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\code\\street fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (1.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\code\\street fighter\\venv\\lib\\site-packages (from matplotlib->stable-baselines3==1.7.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\code\\street fighter\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==1.7.0) (1.17.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\code\\street fighter\\venv\\lib\\site-packages (from pandas->stable-baselines3==1.7.0) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\code\\street fighter\\venv\\lib\\site-packages (from pandas->stable-baselines3==1.7.0) (2025.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from sympy->torch>=1.11->stable-baselines3==1.7.0) (1.3.0)\n",
      "Installing collected packages: importlib-metadata, stable-baselines3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 8.5.0\n",
      "    Uninstalling importlib-metadata-8.5.0:\n",
      "      Successfully uninstalled importlib-metadata-8.5.0\n",
      "  Attempting uninstall: stable-baselines3\n",
      "    Found existing installation: stable-baselines3 2.4.1\n",
      "    Uninstalling stable-baselines3-2.4.1:\n",
      "      Successfully uninstalled stable-baselines3-2.4.1\n",
      "Successfully installed importlib-metadata-4.13.0 stable-baselines3-1.7.0\n"
     ]
    }
   ],
   "source": [
    "%pip install stable-baselines3==1.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna: https://optuna.org/#installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Requirement already satisfied: tqdm in c:\\code\\street fighter\\venv\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Collecting PyYAML\n",
      "  Downloading pyyaml-6.0.3.tar.gz (130 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "Collecting sqlalchemy>=1.4.2\n",
      "  Downloading sqlalchemy-2.0.43-cp38-cp38-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: numpy in c:\\code\\street fighter\\venv\\lib\\site-packages (from optuna) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from optuna) (25.0)\n",
      "Collecting Mako\n",
      "  Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: importlib-resources in c:\\code\\street fighter\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (6.4.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\code\\street fighter\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
      "Requirement already satisfied: importlib-metadata in c:\\code\\street fighter\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (8.5.0)\n",
      "Collecting greenlet>=1\n",
      "  Downloading greenlet-3.1.1-cp38-cp38-win_amd64.whl (298 kB)\n",
      "Requirement already satisfied: colorama in c:\\code\\street fighter\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\code\\street fighter\\venv\\lib\\site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\code\\street fighter\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Building wheels for collected packages: PyYAML\n",
      "  Building wheel for PyYAML (PEP 517): started\n",
      "  Building wheel for PyYAML (PEP 517): finished with status 'done'\n",
      "  Created wheel for PyYAML: filename=PyYAML-6.0.3-cp38-cp38-win_amd64.whl size=45380 sha256=252c5234634e15e50543d1793d271f5c6474ca5cb34a3c84e2f917e6d1062dc8\n",
      "  Stored in directory: c:\\users\\sss\\appdata\\local\\pip\\cache\\wheels\\60\\9b\\bc\\8c54c7c157a008210f4d6ddfce9e9c5274162b18c5832f8e24\n",
      "Successfully built PyYAML\n",
      "Installing collected packages: greenlet, sqlalchemy, Mako, PyYAML, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 PyYAML-6.0.3 alembic-1.14.1 colorlog-6.9.0 greenlet-3.1.1 optuna-4.5.0 sqlalchemy-2.0.43\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Code\\Street Fighter\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shimmy>=2.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: gymnasium>=1.0.0a1 in c:\\code\\street fighter\\venv\\lib\\site-packages (from shimmy>=2.0) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from shimmy>=2.0) (1.24.4)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\code\\street fighter\\venv\\lib\\site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.13.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\code\\street fighter\\venv\\lib\\site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\code\\street fighter\\venv\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium>=1.0.0a1->shimmy>=2.0) (3.20.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Code\\Street Fighter\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"shimmy>=2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Using cached grpcio-1.70.0-cp38-cp38-win_amd64.whl (4.3 MB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from tensorboard) (56.0.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from tensorboard) (2.32.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting protobuf>=3.19.6\n",
      "  Using cached protobuf-5.29.5-cp38-cp38-win_amd64.whl (434 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from tensorboard) (1.24.4)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.20.2)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2025.8.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.2.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4.3)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\diego\\desktop\\street_fighter\\venv\\lib\\site-packages (from tensorboardX) (25.0)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, wheel, werkzeug, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboardX, tensorboard\n",
      "Successfully installed absl-py-2.3.1 cachetools-5.5.2 google-auth-2.40.3 google-auth-oauthlib-1.0.0 grpcio-1.70.0 markdown-3.7 oauthlib-3.3.1 protobuf-5.29.5 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-oauthlib-2.0.0 rsa-4.9.1 tensorboard-2.14.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 werkzeug-3.0.6 wheel-0.45.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\diego\\Desktop\\street_fighter\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorboard tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\Desktop\\street_fighter\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna  # Importing the optimization framework that allows to both train and tune at the same time\n",
    "import torch\n",
    "import os  # For exporting the model\n",
    "from stable_baselines3 import PPO  # PPO algorithm for RL\n",
    "from stable_baselines3.common.evaluation import evaluate_policy  # Metric calculation of agent performance\n",
    "from stable_baselines3.common.monitor import Monitor  # SB3 Monitor for logging\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack  # Vec wrappers to vectorize and frame stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorboard as tb\n",
    "print(tb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories where saved optimization models are going to be saved\n",
    "\n",
    "LOG_DIR = './logs/'  # SB3 has the ability to log out to a support log\n",
    "OPT_DIR = './opt/'  # Location to save every single model after every try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter function to return test hyperparameters - define the objective function\n",
    "\n",
    "def optimize_ppo(trial):  # i.e. objective\n",
    "    return {\n",
    "        # Ranges of possible values that will be optimized\n",
    "        'n_steps': trial.suggest_int('n_steps', 2048, 8192, step=64),  # SB3 requires  the range to be a multiple of 64\n",
    "        'gamma': trial.suggest_loguniform('gamma', 0.8, 0.999),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-4),\n",
    "        'clip_range': trial.suggest_uniform('clip_range', 0.1, 0.4),\n",
    "        'gae_lambda': trial.suggest_uniform('gae_lambda', 0.8, 0.99),\n",
    "    }\n",
    "\n",
    "# When we train we will get a set of best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter function to run a training loop and return mean \n",
    "# device = torch.device(\"cpu\")  # Fuerza CPU\n",
    "\n",
    "def optimize_agent(trial):\n",
    "    # A try - except section can prevent the model from breaking mid-training\n",
    "\n",
    "    model_params = optimize_ppo(trial)  # Variable where we store the parameters from the previous function\n",
    "\n",
    "    # Create environment\n",
    "    env = StreetFighter()\n",
    "    env = Monitor(env, LOG_DIR)  # We specify the location where monitor values will be exported to\n",
    "    env = DummyVecEnv([lambda: env])  # We wrap the environment on a DummyVec\n",
    "    env = VecFrameStack(env, 4, channels_order='last')  # We will stack 4 different frames\n",
    "\n",
    "    # Create training algorithm\n",
    "    # model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=0, **model_params)  # We unpack the model parameters obtained from the tuner and pass them to the PPO model\n",
    "    model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=0, **model_params)\n",
    "    model.learn(total_timesteps=30000)  # We train the model. Longer timesteps means a better model, but also a longer training time. 100k is good, 30k is quick but inaccurate\n",
    "    \n",
    "    # Evaluate model\n",
    "    mean_reward = evaluate_policy(model, env, n_eval_episodes=5)  # We unpack the results obtained from evaluate policy. We will evaluate the model on 5 different games (more == better)\n",
    "    env.close()\n",
    "\n",
    "    SAVE_PATH = os.path.join(OPT_DIR, 'trial_{}_best_model'.format(trial.number))\n",
    "    model.save(SAVE_PATH)  # We save all models to get the best one\n",
    "\n",
    "    # We have to give optuna a value it expects, so if its a tuple we return only an int\n",
    "    if isinstance(mean_reward, (tuple, list)):\n",
    "        mean_reward = mean_reward[0]\n",
    "\n",
    "    return mean_reward \n",
    "    try:\n",
    "        pass\n",
    "\n",
    "    except Exception as e:\n",
    "        return -1000  # Model did not work, we resume training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()  # We close any environment that could be open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:08:45,923] A new study created in memory with name: no-name-0d104e47-dc18-4027-9067-3149125ecadc\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_23284\\2097929532.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'gamma': trial.suggest_loguniform('gamma', 0.8, 0.999),\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_23284\\2097929532.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-4),\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_23284\\2097929532.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'clip_range': trial.suggest_uniform('clip_range', 0.1, 0.4),\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_23284\\2097929532.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'gae_lambda': trial.suggest_uniform('gae_lambda', 0.8, 0.99),\n",
      "c:\\Users\\diego\\Desktop\\street_fighter\\venv\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:278: UserWarning: Path 'opt' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n",
      "[I 2025-09-29 12:13:23,597] Trial 0 finished with value: 176.0 and parameters: {'n_steps': 2944, 'gamma': 0.9197780647949918, 'learning_rate': 1.7432714049131067e-05, 'clip_range': 0.16838554334843275, 'gae_lambda': 0.8397361146181571}. Best is trial 0 with value: 176.0.\n"
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "\n",
    "study = optuna.create_study(direction='maximize')  # We create the experiment / study that seeks to maximize the mean reward\n",
    "study.optimize(optimize_agent, n_trials=1, n_jobs=1)  # We optimize the study based on the agent created, and how many sets we will set. 10 is good for testing, 100+ is recommended for a good model\n",
    "\n",
    "# NOTE: Using 100k timesteps on the model and 100 trials can take a long time to train (depending on the strength of the gpu from a few hours to a couple of days)\n",
    "\n",
    "# If we wanted to speed things up whilst keeping accuracy, we could raise n_jobs, however retro does not support more than one environment at once. We can fix\n",
    "# this by using retrowrapper: https://github.com/MaxStrange/retrowrapper. This allows for multiple instances at once which exponentially speeds trainig up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_steps': 2944,\n",
       " 'gamma': 0.9197780647949918,\n",
       " 'learning_rate': 1.7432714049131067e-05,\n",
       " 'clip_range': 0.16838554334843275,\n",
       " 'gae_lambda': 0.8397361146181571}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To pass it through a model we use\n",
    "# model = PPO.load(os.path.join(OPT_DIR, 'trial_0_best_model.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_video = {\n",
    "    'n_steps': 7488,\n",
    "    'gamma': 0.9085173842732223,\n",
    "    'learning_rate': 5e-7,\n",
    "    'clip_range': 0.39105070719865653,\n",
    "    'gae_lambda': 0.8376637411768156\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base callback\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Callback\n",
    "\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "    \n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)  # We will save the model every 10k steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = study.best_params\n",
    "model_params['learning_rate'] = 5e-7  # Might improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "\n",
    "# env.close()\n",
    "env = StreetFighter()\n",
    "env = Monitor(env, LOG_DIR)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2d8fdc370a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, **model_params)\n",
    "\n",
    "trial_opt_DIR = \"opt/trial_0_best_model.zip\"\n",
    "\n",
    "model.load(os.path.join(OPT_DIR, 'trial_0_best_model.zip'))  # We reload previous weights from HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/PPO_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 274  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 10   |\n",
      "|    total_timesteps | 2944 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 5888         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.319297e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.168        |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | 0.00564      |\n",
      "|    learning_rate        | 5e-07        |\n",
      "|    loss                 | 7.99         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -7.79e-05    |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 7.03e+03     |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 8832         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.597089e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.168        |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | -0.000354    |\n",
      "|    learning_rate        | 5e-07        |\n",
      "|    loss                 | 0.56         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -6.18e-05    |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 7.03e+03      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 198           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 59            |\n",
      "|    total_timesteps      | 11776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4544297e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | -0.00285      |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 5.25          |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00011      |\n",
      "|    value_loss           | 25.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 7.03e+03      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 193           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 75            |\n",
      "|    total_timesteps      | 14720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3066406e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00435       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 0.186         |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -4.3e-05      |\n",
      "|    value_loss           | 42.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.05e+03     |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 190          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 17664        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.979694e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.168        |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | 0.00239      |\n",
      "|    learning_rate        | 5e-07        |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000148    |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.05e+03      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 188           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 109           |\n",
      "|    total_timesteps      | 20608         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1691036e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00259       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 0.217         |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.0001       |\n",
      "|    value_loss           | 34.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.05e+03     |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 185          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.448189e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.168        |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | -0.00138     |\n",
      "|    learning_rate        | 5e-07        |\n",
      "|    loss                 | 0.353        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.000112    |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.05e+03      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 184           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 143           |\n",
      "|    total_timesteps      | 26496         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0338642e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00321       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 6.67          |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -6.6e-05      |\n",
      "|    value_loss           | 50.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.05e+03     |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 183          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 29440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.225537e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.168        |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | 0.00622      |\n",
      "|    learning_rate        | 5e-07        |\n",
      "|    loss                 | 65.1         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -2.95e-05    |\n",
      "|    value_loss           | 49.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.05e+03     |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 182          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 177          |\n",
      "|    total_timesteps      | 32384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.566141e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.168        |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | 0.00241      |\n",
      "|    learning_rate        | 5e-07        |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -9.52e-05    |\n",
      "|    value_loss           | 82.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.05e+03      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 180           |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 195           |\n",
      "|    total_timesteps      | 35328         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5867934e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00212       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 0.613         |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.000154     |\n",
      "|    value_loss           | 46.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.05e+03    |\n",
      "|    ep_rew_mean          | 176         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 180         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 38272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 8.60783e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.168       |\n",
      "|    entropy_loss         | -8.32       |\n",
      "|    explained_variance   | 0.00568     |\n",
      "|    learning_rate        | 5e-07       |\n",
      "|    loss                 | 5.91        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -9.86e-05   |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.05e+03     |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 179          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 41216        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.843439e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.168        |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | 0.00686      |\n",
      "|    learning_rate        | 5e-07        |\n",
      "|    loss                 | 0.321        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000106    |\n",
      "|    value_loss           | 50.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.05e+03      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 178           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 247           |\n",
      "|    total_timesteps      | 44160         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2678195e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00136       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 18.3          |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -6.75e-05     |\n",
      "|    value_loss           | 58.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.52e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 178           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 264           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0097536e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | -0.000555     |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 40.2          |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -5.93e-05     |\n",
      "|    value_loss           | 69.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.52e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 177           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 281           |\n",
      "|    total_timesteps      | 50048         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.4710697e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00273       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 34.8          |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.000119     |\n",
      "|    value_loss           | 19.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+04     |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 176          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 299          |\n",
      "|    total_timesteps      | 52992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.767296e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.168        |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | 0.00807      |\n",
      "|    learning_rate        | 5e-07        |\n",
      "|    loss                 | 9.8          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -6.58e-05    |\n",
      "|    value_loss           | 44.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+04     |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 176          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 317          |\n",
      "|    total_timesteps      | 55936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.668778e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.168        |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | -0.00238     |\n",
      "|    learning_rate        | 5e-07        |\n",
      "|    loss                 | 0.0391       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -7.2e-05     |\n",
      "|    value_loss           | 12.1         |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1.52e+04       |\n",
      "|    ep_rew_mean          | 176            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 176            |\n",
      "|    iterations           | 20             |\n",
      "|    time_elapsed         | 333            |\n",
      "|    total_timesteps      | 58880          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.17910095e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.168          |\n",
      "|    entropy_loss         | -8.32          |\n",
      "|    explained_variance   | 0.00481        |\n",
      "|    learning_rate        | 5e-07          |\n",
      "|    loss                 | 9.25           |\n",
      "|    n_updates            | 190            |\n",
      "|    policy_gradient_loss | -0.000101      |\n",
      "|    value_loss           | 38.1           |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.49e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 175           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 351           |\n",
      "|    total_timesteps      | 61824         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1648679e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.000959      |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 0.351         |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.000125     |\n",
      "|    value_loss           | 27.4          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.49e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 175           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 369           |\n",
      "|    total_timesteps      | 64768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5955708e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00192       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 2.65          |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -5.98e-05     |\n",
      "|    value_loss           | 17.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.33e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 174           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 387           |\n",
      "|    total_timesteps      | 67712         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2198868e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | -0.000699     |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 2.39          |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000138     |\n",
      "|    value_loss           | 20.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.33e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 174           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 405           |\n",
      "|    total_timesteps      | 70656         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6235257e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.000645      |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 1.28          |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.000104     |\n",
      "|    value_loss           | 36.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.33e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 173           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 423           |\n",
      "|    total_timesteps      | 73600         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8774806e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00459       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 1.29          |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -6.73e-05     |\n",
      "|    value_loss           | 47            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.33e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 173           |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 439           |\n",
      "|    total_timesteps      | 76544         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.4002435e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00488       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 55.5          |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | -0.000137     |\n",
      "|    value_loss           | 35.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.33e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 174           |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 456           |\n",
      "|    total_timesteps      | 79488         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7837206e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00207       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 262           |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -6.56e-05     |\n",
      "|    value_loss           | 55.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.36e+04     |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 173          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 474          |\n",
      "|    total_timesteps      | 82432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.663125e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.168        |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | 0.00661      |\n",
      "|    learning_rate        | 5e-07        |\n",
      "|    loss                 | 2.42         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -9.29e-05    |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+04    |\n",
      "|    ep_rew_mean          | 176         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 172         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 493         |\n",
      "|    total_timesteps      | 85376       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 9.49289e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.168       |\n",
      "|    entropy_loss         | -8.32       |\n",
      "|    explained_variance   | 0.00199     |\n",
      "|    learning_rate        | 5e-07       |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.000127   |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.25e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 172           |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 511           |\n",
      "|    total_timesteps      | 88320         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3299468e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.002         |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 0.0504        |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.000114     |\n",
      "|    value_loss           | 24            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.25e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 172           |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 528           |\n",
      "|    total_timesteps      | 91264         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3956783e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00295       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 2.27          |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -7.21e-05     |\n",
      "|    value_loss           | 19.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+04     |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 172          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 545          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.081807e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.168        |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | 0.00746      |\n",
      "|    learning_rate        | 5e-07        |\n",
      "|    loss                 | 3.88         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -6.21e-05    |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.25e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 172           |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 562           |\n",
      "|    total_timesteps      | 97152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.8786095e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.0053        |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 4.93          |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -7.56e-05     |\n",
      "|    value_loss           | 68.4          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.25e+04      |\n",
      "|    ep_rew_mean          | 176           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 172           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 580           |\n",
      "|    total_timesteps      | 100096        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3233663e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.168         |\n",
      "|    entropy_loss         | -8.32         |\n",
      "|    explained_variance   | 0.00436       |\n",
      "|    learning_rate        | 5e-07         |\n",
      "|    loss                 | 4.49          |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -4.81e-05     |\n",
      "|    value_loss           | 69.9          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2d8a9394df0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.learn(total_timesteps=100000, callback=callback)  # Bigger is better, for example 5 million\n",
    "# model.learn(total_timesteps=5000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing and Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load and visualize the training result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('./train/best_model_100000.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, render=False, n_eval_episodes=5)\n",
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58.]\n",
      "[58.]\n",
      "[46.]\n",
      "[78.]\n",
      "[56.]\n",
      "[57.]\n",
      "[12.]\n",
      "[72.]\n",
      "[80.]\n",
      "[58.]\n",
      "[56.]\n",
      "[12.]\n",
      "[32.]\n",
      "[56.]\n",
      "[58.]\n",
      "[74.]\n",
      "[40.]\n",
      "[80.]\n",
      "[24.]\n",
      "[22.]\n",
      "[56.]\n",
      "[2.]\n",
      "[54.]\n",
      "[70.]\n",
      "[137.]\n",
      "[66.]\n",
      "[70.]\n",
      "[12.]\n",
      "[50.]\n",
      "[50.]\n",
      "[105.]\n"
     ]
    }
   ],
   "source": [
    "# Test to see everything working\n",
    "\n",
    "# Reset game to starting state\n",
    "obs = env.reset()\n",
    "\n",
    "# Flag to false\n",
    "done = False\n",
    "\n",
    "# We only play one game\n",
    "for game in range(1):\n",
    "\n",
    "    # If game is not over.\n",
    "    while not done:\n",
    "        if done:\n",
    "            # We reset the game\n",
    "            obs = env.reset()\n",
    "\n",
    "        # Render environment\n",
    "        env.render()\n",
    "\n",
    "        action = model.predict(obs)[0]\n",
    "        obs, reward, done, info = env.step(action)\n",
    "\n",
    "        # We slow down the renders so they are watchable\n",
    "        time.sleep(0.01)\n",
    "\n",
    "        # We print the reward\n",
    "        if reward > 0:\n",
    "            print(reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
